{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rrp6Kj0x8Vc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================================ #\n",
        "#                              Mount Drive                                     #\n",
        "# ============================================================================ #\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-XWI5ljXt-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================================ #\n",
        "#                              Unzip archive                                   #\n",
        "# ============================================================================ #\n",
        "\n",
        "# ============================================================================ #\n",
        "# Unzip archive\n",
        "!rm -fr /content/bioinf-project/  > /dev/null 2>&1\n",
        "!unzip -q -o /content/bioinf-project.zip -d /content/ > /dev/null 2>&1\n",
        "\n",
        "# ============================================================================ #\n",
        "# Setting environment using make tool and a Makefile file\n",
        "!cp -r /content/bioinf-project/* /content > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98HhJMO50eqY",
        "colab_type": "code",
        "outputId": "4e5c13bc-5947-433d-a801-8a384259037b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ============================================================================ #\n",
        "#                          INSTALLING SOME DEPENDENCIES                        #\n",
        "# ============================================================================ #\n",
        "\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.5)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5f/a1a02695b96d0e09c38abf7d1576b137979cea3d060d60891622cf61276d/google_auth-1.10.1-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed google-auth-1.10.1 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmfSkB0R_CIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "67742d99-31b7-4240-ab84-d1ff97ce36e5"
      },
      "source": [
        "# Run genes fusions classifier with either '-h' or '--help'\n",
        "# flags in order to show tool's menu for let user\n",
        "# knowing how to employ it.\n",
        "\n",
        "!make -f Makefile run_help_classifier_tool"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clear\n",
            "\u001b[H\u001b[2J# cp tests/script_pipeline_test.py main.py\n",
            "ln -sfn main.py genes_fusions_classifier\n",
            "chmod u+x genes_fusions_classifier\n",
            "python3  genes_fusions_classifier -h\n",
            "2020-01-19 13:23:46.902340: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-01-19 13:23:46.903648: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-01-19 13:23:46.903695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Using TensorFlow backend.\n",
            "usage: genes_fusions_classifier [-h] [--subdir SUBDIR] [--validation]\n",
            "                                [--train] [--test] [--batch_size BATCH_SIZE]\n",
            "                                [--num_epochs NUM_EPOCHS] [--lr LR]\n",
            "                                [--sequence_type {dna,protein}]\n",
            "                                [--pretrained_model PRETRAINED_MODEL]\n",
            "                                [--network_parameters NETWORK_PARAMETERS]\n",
            "                                [--load_network LOAD_NETWORK] [--onehot_flag]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --subdir SUBDIR       Checkpoints directory\n",
            "  --validation          Perform Holdout-Validation for hyperparameter\n",
            "                        selection\n",
            "  --train               Train model on whole training data and save it\n",
            "  --test                Test saved model, in the specified subdir, on test bin\n",
            "  --batch_size BATCH_SIZE\n",
            "                        Number of sample for each training step\n",
            "  --num_epochs NUM_EPOCHS\n",
            "                        Number of epochs before halting the training\n",
            "  --lr LR               Learning rate coefficient\n",
            "  --sequence_type {dna,protein}\n",
            "                        Type of sequence to process in the model: \"dna\" or\n",
            "                        \"protein\"\n",
            "  --pretrained_model PRETRAINED_MODEL\n",
            "                        Path where to find the weights of a pre-trained model\n",
            "  --network_parameters NETWORK_PARAMETERS\n",
            "                        File with neural network parameters, either json or\n",
            "                        yaml format\n",
            "  --load_network LOAD_NETWORK\n",
            "                        Architecture's name. According to this a different\n",
            "                        model is loaded\n",
            "  --onehot_flag         If true, it encodes data by using one-hot encodin,\n",
            "                        otherwise embedding representation is used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OP0kigsMM1Cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31679456-c7cc-49e2-b239-34fd3705927f"
      },
      "source": [
        "# A run example\n",
        "\n",
        "!python3 main.py \\\n",
        "  --validation \\\n",
        "  --sequence_type protein \\\n",
        "  --batch_size 32 \\\n",
        "  --num_epochs 50 \\\n",
        "  --lr 1e-3 \\\n",
        "  --network_parameters /content/models/ModelEmbeddingBidirect.json \\\n",
        "  --load_network ModelEmbeddingBidirect \\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-19 13:24:18.994360: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-01-19 13:24:18.994483: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-01-19 13:24:18.994508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Using TensorFlow backend.\n",
            "----> Set up analysis environment.\n",
            " [*] Creating environment for saving current analysis results...\n",
            "2020-01-19 13:24:20,385:utils.setup_analysis_environment_util:logger initialization done!\n",
            "2020-01-19 13:24:20,385:utils.setup_analysis_environment_util:Namespace(batch_size=32, load_network='ModelEmbeddingBidirect', lr=0.001, network_parameters='/content/models/ModelEmbeddingBidirect.json', num_epochs=50, onehot_flag=False, pretrained_model=None, sequence_type='protein', subdir='20200119_132420', test=False, train=False, validation=True)\n",
            "Namespace(batch_size=32, load_network='ModelEmbeddingBidirect', lr=0.001, network_parameters='/content/models/ModelEmbeddingBidirect.json', num_epochs=50, onehot_flag=False, pretrained_model=None, sequence_type='protein', subdir='20200119_132420', test=False, train=False, validation=True)\n",
            "2020-01-19 13:24:20,385:utils.setup_analysis_environment_util:\n",
            "{\n",
            "    \"batch_size\": 32,\n",
            "    \"epochs\": 30,\n",
            "    \"learning_rate\": 0.01,\n",
            "    \"embedding_size\": 16,\n",
            "    \"lstm_units\": 8,\n",
            "    \"embedding_regularizer\": 1e-06,\n",
            "    \"l1_regularizer\": 0.01,\n",
            "    \"l2_regularizer\": 0.01,\n",
            "    \"last_dense_l2_regularizer\": 2e-06,\n",
            "    \"lstm_input_dropout\": 0.2,\n",
            "    \"lstm_1_dropout_rate\": 0.2,\n",
            "    \"lstm_2_dropout_rate\": 0.2,\n",
            "    \"attention_dropout\": 0.1,\n",
            "    \"recurrent_dropout_rate\": 0.2,\n",
            "    \"maxlen\": 3219,\n",
            "    \"input_dim\": 5,\n",
            "    \"output_dim\": 8,\n",
            "    \"dropout_rates\": [\n",
            "        0.0,\n",
            "        0.0\n",
            "    ],\n",
            "    \"seeds\": [\n",
            "        42,\n",
            "        17,\n",
            "        103,\n",
            "        111,\n",
            "        19\n",
            "    ],\n",
            "    \"optimizer\": \"ADAM\",\n",
            "    \"metrics\": [\n",
            "        \"accuracy\",\n",
            "        \"binary_crossentropy\"\n",
            "    ],\n",
            "    \"clip_norm\": 1.0,\n",
            "    \"loss\": \"binary_crossentropy\",\n",
            "    \"mask_zero\": false,\n",
            "    \"pretrained_model\": null\n",
            "}\n",
            "{'columns_names': ['Sequences',\n",
            "                   'Count',\n",
            "                   'Unnamed: 0',\n",
            "                   'Label',\n",
            "                   'Translated_sequences',\n",
            "                   'Protein_length'],\n",
            " 'path': './data/bins_translated',\n",
            " 'sequence_type': 'protein',\n",
            " 'test_bins': [5],\n",
            " 'train_bins': [1, 2, 3],\n",
            " 'val_bins': [4]}\n",
            "{'maxlen': 3219, 'onehot_flag': False, 'padding': 'post'}\n",
            "2020-01-19 13:24:20,386:utils.setup_analysis_environment_util:----> Dataset Load.\n",
            "2020-01-19 13:24:20,386:utils.setup_analysis_environment_util: [*] Loading Training Bins...\n",
            " > Adding bin: ./data/bins_translated/bin_1_translated.csv... Done.\n",
            "2020-01-19 13:24:20,420:utils.setup_analysis_environment_util: > Added bin: ./data/bins_translated/bin_1_translated.csv, Done.\n",
            " > Adding bin: ./data/bins_translated/bin_2_translated.csv... Done.\n",
            "2020-01-19 13:24:20,441:utils.setup_analysis_environment_util: > Added bin: ./data/bins_translated/bin_2_translated.csv, Done.\n",
            " > Adding bin: ./data/bins_translated/bin_3_translated.csv... Done.\n",
            "2020-01-19 13:24:20,465:utils.setup_analysis_environment_util: > Added bin: ./data/bins_translated/bin_3_translated.csv, Done.\n",
            "2020-01-19 13:24:20,471:utils.setup_analysis_environment_util: [*] Loading Validation Bins...\n",
            " > Adding bin: ./data/bins_translated/bin_4_translated.csv... Done.\n",
            "2020-01-19 13:24:20,498:utils.setup_analysis_environment_util: > Added bin: ./data/bins_translated/bin_4_translated.csv, Done.\n",
            "2020-01-19 13:24:20,499:utils.setup_analysis_environment_util: [*] Loading Test Bins...\n",
            " > Adding bin: ./data/bins_translated/bin_5_translated.csv... Done.\n",
            "2020-01-19 13:24:20,521:utils.setup_analysis_environment_util: > Added bin: ./data/bins_translated/bin_5_translated.csv, Done.\n",
            "2020-01-19 13:24:20,523:utils.setup_analysis_environment_util: [*] Dataset Load: Done.\n",
            "2020-01-19 13:24:20,523:utils.setup_analysis_environment_util:----> Preprocess Data.\n",
            "2020-01-19 13:24:20,523:utils.setup_analysis_environment_util: [*] Preprocessing data...\n",
            "2020-01-19 13:24:21,090:utils.setup_analysis_environment_util: [*] Preprocess Data: Done.\n",
            "2020-01-19 13:24:21,090:utils.setup_analysis_environment_util:----> Perform Analysis...\n",
            "2020-01-19 13:24:21,090:utils.setup_analysis_environment_util: [*] Performing first phase (holdout)...\n",
            "2020-01-19 13:24:21,091:utils.setup_analysis_environment_util:Training on bins: [1, 2, 3], validation on [4]\n",
            "2020-01-19 13:24:21.321167: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-01-19 13:24:23,349:utils.setup_analysis_environment_util:> build model (holdout).\n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:Model: \"model\"\n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:==================================================================================================\n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:input_1 (InputLayer)            [(None, 3219)]       0                                            \n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,524:utils.setup_analysis_environment_util:masking (Masking)               (None, 3219)         0           input_1[0][0]                    \n",
            "2020-01-19 13:24:23,525:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,525:utils.setup_analysis_environment_util:embedding (Embedding)           (None, 3219, 16)     336         masking[0][0]                    \n",
            "2020-01-19 13:24:23,525:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,525:utils.setup_analysis_environment_util:activation_1 (Activation)       (None, 3219, 16)     0           embedding[0][0]                  \n",
            "2020-01-19 13:24:23,525:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:bidirectional (Bidirectional)   (None, 3219, 16)     1600        activation_1[0][0]               \n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:dropout (Dropout)               (None, 3219, 16)     0           bidirectional[0][0]              \n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:bidirectional_1 (Bidirectional) (None, 3219, 16)     1600        dropout[0][0]                    \n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,526:utils.setup_analysis_environment_util:dropout_1 (Dropout)             (None, 3219, 16)     0           bidirectional_1[0][0]            \n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:activation (Activation)         (None, 3219, 16)     0           embedding[0][0]                  \n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:concatenate (Concatenate)       (None, 3219, 48)     0           dropout_1[0][0]                  \n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:                                                                 dropout[0][0]                    \n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:                                                                 activation[0][0]                 \n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,527:utils.setup_analysis_environment_util:attlayer (AttentionWeightedAver (None, 48)           48          concatenate[0][0]                \n",
            "2020-01-19 13:24:23,528:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,528:utils.setup_analysis_environment_util:dense (Dense)                   (None, 1)            49          attlayer[0][0]                   \n",
            "2020-01-19 13:24:23,528:utils.setup_analysis_environment_util:==================================================================================================\n",
            "2020-01-19 13:24:23,529:utils.setup_analysis_environment_util:Total params: 3,633\n",
            "2020-01-19 13:24:23,529:utils.setup_analysis_environment_util:Trainable params: 3,633\n",
            "2020-01-19 13:24:23,529:utils.setup_analysis_environment_util:Non-trainable params: 0\n",
            "2020-01-19 13:24:23,529:utils.setup_analysis_environment_util:__________________________________________________________________________________________________\n",
            "2020-01-19 13:24:23,820:utils.setup_analysis_environment_util:> train model (holdout)...\n",
            "Train on 1385 samples, validate on 463 samples\n",
            "Epoch 1/50\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "1376/1385 [============================>.] - ETA: 0s - loss: 1.5340 - accuracy: 0.5908 - f1_m: 0.5030 - precision_m: 0.5014 - recall_m: 0.5871"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ5m6jkVZb-L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Toward Data Science(Medium) articles, blogs:\n",
        "- https://towardsdatascience.com/using-git-with-colab-via-ssh-175e8f3751ec\n",
        "\n",
        "### Tensorflow Tutorials:\n",
        " - https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        " - https://www.tensorflow.org/guide/keras/train_and_evaluate"
      ]
    }
  ]
}